# ğŸ§  Bajaj Finserv AMC RAG Chatbot
[![Next.js](https://img.shields.io/badge/Next.js-black?logo=next.js\&logoColor=white)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-61DAFB?logo=react\&logoColor=black)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi\&logoColor=white)](https://fastapi.tiangolo.com/)
[![LangChain](https://img.shields.io/badge/LangChain-blue?logo=data\:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzYiIGhlaWdodD0iMzYiIHZpZXdCb3g9IjAgMCAzNiAzNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMu+b3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTI4IDZIMTNWMTJIMjhaIiBmaWxsPSIjRkZGIi8+CjxwYXRoIGQ9Ik0yMiAxOEgxM1YyNEgyOFYxOFoiIGZpbGw9IiNGRkYiLz4KPHBhdGggZD0iTTI4IDI0SDEzVjMwSDI4VjI0WiIgZmlsbD0iI0ZGRiIvPgo8L3N2Zz4=)](https://www.langchain.com/)
[![Gemini](https://img.shields.io/badge/Gemini-AI-orange?logo=ai\&logoColor=white)](https://developers.google.com/vertex-ai)
[![Qdrant](https://img.shields.io/badge/Qdrant-VectorDB-red?logo=qdrant\&logoColor=white)](https://qdrant.io/)
[![Vercel](https://img.shields.io/badge/Vercel-black?logo=vercel\&logoColor=white)](https://vercel.com/)
[![Render](https://img.shields.io/badge/Render-deepblue?logo=render\&logoColor=white)](https://render.com/)

ğŸ”— **Live Demo:** [bajaj-finserv-assingment.vercel.app](https://bajaj-finserv-assingment.vercel.app)

---

## ğŸš€ Overview

The **Bajaj Finserv AMC RAG Chatbot** is an intelligent **Retrieval-Augmented Generation (RAG)** system that answers complex questions about **Bajaj AMC Fund Factsheets**.

ğŸ’¡ **Key Features:**

* Multi-modal understanding (text + charts + tables + visuals)
* Context-aware financial reasoning
* Explainable AI responses grounded in the source documents

---

## ğŸ§© System Architecture

<img src="ArchitectureDiagram.png" alt="System Architecture" width="100%"/>

> **Workflow:**
> ğŸ“ PDF upload â†’ ğŸ–¼ï¸ Image processing â†’ ğŸ¤– Gemini multi-modal extraction â†’ ğŸ”— Vector storage in Qdrant â†’ ğŸ’¬ Chatbot response generation

---

## âš™ï¸ Data Ingestion Pipeline

When a user uploads a **fund factsheet PDF**, hereâ€™s the behind-the-scenes process:

1. ğŸ“¤ **Upload** â€” Sent to the `/upload` endpoint.
2. ğŸ–¼ï¸ **PDF â†’ Image** conversion via `PyMuPDF`.
3. ğŸ¤– **Image-to-text extraction** using **Gemini-2.0-Flash-Lite (Vision)**. Captures **text, tables, charts, visuals** â€” no OCR needed.
4. ğŸ§© **Chunking** â€” Segments extracted data into contextual pieces.
5. ğŸ“š **Vectorization** â€” Each chunk embedded using **Gemini Embedding Model**.
6. ğŸ’¾ **Storage** â€” Saved in **Qdrant VectorDB** for retrieval.

### ğŸ” Why Gemini Vision?

| ğŸ”¹ Feature       | Gemini Vision ğŸ§                   | Traditional OCR ğŸ§¾ |
| :--------------- | :-------------------------------- | :----------------- |
| Charts & Tables  | Understands structure & semantics | Plain text only    |
| Visual Reasoning | Interprets icons, layouts, graphs | Not supported      |
| Setup            | Requires API access               | Simple             |
| Accuracy         | High for multi-modal content      | Limited            |
| Best Use Case    | Mixed-format documents            | Pure-text scans    |

---

## ğŸ’¬ Chat Retrieval & Response Flow

1. ğŸ“¨ **Query** â†’ Gemini-2.5-Flash agent
2. ğŸ” **Decision** â†’ Retrieve context (RAG) or answer directly
3. ğŸ“ˆ **Retrieval** â†’ MMR (Maximal Marginal Relevance) from Qdrant
4. ğŸ¤– **Response Generation** â†’ Context + Query â†’ Gemini reasoning
5. ğŸ’¬ **Answer Displayed** â†’ Users see grounded, contextual response
6. ğŸ” **Transparency** â†’ Click `...` to view retrieved context

---

## ğŸ§± Tech Stack

| Layer               | Tools & Libraries                                                               | Hosting / Notes        |
| :------------------ | :------------------------------------------------------------------------------ | :--------------------- |
| **Backend**         | FastAPI, LangChain, Google Generative AI, Qdrant Client, PyMuPDF                | Hosted on **Render**   |
| **Frontend**        | Next.js, React, Tailwind CSS, Lucide Icons                                      | Hosted on **Vercel**   |
| **AI Models**       | Gemini-2.0-Flash-Lite (Vision), Gemini-2.5-Flash (Text), Gemini Embedding Model | API-based              |
| **Database**        | Qdrant Vector Database                                                          | Managed cloud instance |
| **Search Strategy** | Maximal Marginal Relevance (MMR)                                                | RAG Retrieval          |

---

## ğŸ” Environment Configuration

Create `.env` in both backend & frontend:

```bash
GOOGLE_API_KEY=your_google_api_key_here
QDRANT_API_KEY=your_qdrant_api_key_here
QDRANT_API_KEY_LOCATION=your_qdrant_cluster_url
TAVILY_API_KEY=your_tavily_api_key_here
COLLECTION_NAME=your_qdrant_collection_name_here
```

âš ï¸ **Required for ingestion, retrieval, and chat functionality.**

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ pipeline_for_document_ingestion/
â”‚   â”‚   â””â”€â”€ docsProcessing.py
â”‚   â””â”€â”€ rag_pipeline/
â”‚       â”œâ”€â”€ google_agent.py
â”‚       â””â”€â”€ tools.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ next.config.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ upload/page.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”‚   â”œâ”€â”€ ThemeContext.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadContext.tsx
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ Notification.tsx
â”‚   â”‚       â”œâ”€â”€ ChatContainer.tsx
â”‚   â”‚       â””â”€â”€ ContextViewer.tsx
â””â”€â”€ scripts/
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone

```bash
git clone https://github.com/SujalPore47/BAJAJ_Finserv_Assingment-.git
```

### 2ï¸âƒ£ Backend

```bash
cd backend
python -m venv venv
# Activate venv
pip install --upgrade pip
pip install --no-deps google-generativeai google-ai-generativelanguage langchain-google-genai
pip install --no-deps langchain langchain-core langchain-qdrant langgraph langgraph-checkpoint langgraph-prebuilt langgraph-sdk langsmith
pip install --no-cache-dir --no-deps -r requirements.txt
```

> âš ï¸ Update `CORS` in `backend/main.py` for localhost during development.

### 3ï¸âƒ£ Frontend

```bash
cd frontend
npm install
```

> âš ï¸ Update `API URLs` in `frontend/next.config.ts` for local backend.

---

## â–¶ï¸ Running

**Backend:**

```bash
cd backend
uvicorn main:app --reload
```

**Frontend:**

```bash
cd frontend
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

---

## ğŸŒ— Frontend Highlights

âœ¨ Dark/Light Mode based upon browsers theme
ğŸ“¤ File upload with real-time feedback
ğŸ” View AI context transparency (`...`)
âš¡ Smooth Tailwind + Lucide animations

---

## ğŸŒ Deployment

| Component     | Platform     | Notes                                                                                        |
| :------------ | :----------- | :------------------------------------------------------------------------------------------- |
| **Frontend**  | Vercel       | Live App: [bajaj-finserv-assingment.vercel.app](https://bajaj-finserv-assingment.vercel.app) |
| **Backend**   | Render       | API endpoints hosted, accessible to frontend                                                 |
| **Vector DB** | Qdrant Cloud | Managed vector database for RAG retrieval                                                    |

---

## ğŸ”® Future Enhancements

* ğŸ“š Multi-PDF ingestion + cross-document reasoning
* ğŸ§  Domain-adaptive financial embeddings
* âš¡ Semantic caching for repeated queries

---

## ğŸ‘¤ Author

**Sujal Pore**
ğŸ”— [GitHub](https://github.com/SujalPore47)
ğŸ’¬ Open to collaboration, feedback, and optimizations!

---
